# Coreset Distillation Experiments

This repository contains experiments and implementations related to **coreset distillation techniques** in machine learning. Coreset distillation is a method used to reduce large datasets into smaller, representative subsets (coresets) that preserve essential information for training deep learning models.

## 🚀 Purpose

The goal of this project is to **test, evaluate, and improve coreset distillation methods** for scalable and efficient model training, particularly in security-focused domains like **IoT network traffic analysis**.

## 🧪 Features

- Implementation of various coreset selection strategies
- Support for the **CIC IoT 2023** dataset (Canadian Institute for Cybersecurity)
- Evaluation of coreset quality in the context of **anomaly and intrusion detection**
- Integration with popular deep learning frameworks (e.g., PyTorch, TensorFlow)
- Reproducible experiment scripts and configurations

## 🛠 Techniques Explored

- Herding
- K-Center Greedy
- Gradient Matching
- Dataset Distillation
- Clustering-based Selection
- Submodular Optimization

## 📁 Directory Structure

