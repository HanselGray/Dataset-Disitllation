# Coreset Distillation Experiments

This repository contains experiments and implementations related to **coreset distillation techniques** in machine learning. Coreset distillation is a method used to reduce large datasets into smaller, representative subsets (coresets) that preserve essential information for training deep learning models.

## ğŸš€ Purpose

The goal of this project is to **test, evaluate, and improve coreset distillation methods** for scalable and efficient model training, particularly in security-focused domains like **IoT network traffic analysis**.

## ğŸ§ª Features

- Implementation of various coreset selection strategies
- Support for the **CIC IoT 2023** dataset (Canadian Institute for Cybersecurity)
- Evaluation of coreset quality in the context of **anomaly and intrusion detection**
- Integration with popular deep learning frameworks (e.g., PyTorch, TensorFlow)
- Reproducible experiment scripts and configurations

## ğŸ›  Techniques Explored

- Herding
- K-Center Greedy
- Gradient Matching
- Dataset Distillation
- Clustering-based Selection
- Submodular Optimization

## ğŸ“ Directory Structure

